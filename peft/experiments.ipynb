{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef4e2ef-9b7a-493e-a56d-ce916568ecc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\croxw\\anaconda3\\lib\\site-packages (4.39.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\croxw\\anaconda3\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\croxw\\anaconda3\\lib\\site-packages (0.43.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from accelerate) (2.2.0+cu121)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from langchain) (3.9.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
      "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.38-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.0-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.7/50.7 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\croxw\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "   ---------------------------------------- 0.0/810.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/810.5 kB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 481.3/810.5 kB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  809.0/810.5 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 810.5/810.5 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 31.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 38.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 273.9/273.9 kB ? eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.9/86.9 kB ? eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB ? eta 0:00:00\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB ? eta 0:00:00\n",
      "Downloading orjson-3.10.0-cp311-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, orjson, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate bitsandbytes langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743c3e8-4d91-47ab-82d0-7cd76f518c0a",
   "metadata": {},
   "source": [
    "### Первым шагом попробуем инициализировать модель на устройстве и потестируем промпты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc41487f-0b2a-4417-be62-7dc552446318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.39.2\n",
      "- Platform: Windows-10-10.0.22631-SP0\n",
      "- Python version: 3.11.5\n",
      "- Huggingface_hub version: 0.22.2\n",
      "- Safetensors version: 0.4.2\n",
      "- Accelerate version: 0.28.0\n",
      "- Accelerate config: \tnot found\n",
      "- PyTorch version (GPU?): 2.2.0+cu121 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5c80c-0327-46a0-8551-218b29a0f484",
   "metadata": {},
   "source": [
    "### Загрузим модель на локальную машину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f309caad-157b-483d-abf5-a723f874126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025705c4dab747ffa0971ae354ddd2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\croxw\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\croxw\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fed7bb16a6946d89d7a411ff8980963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4684555d90494791c5fee3c68bad9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26769974e6144a4e96b2f9ae69214705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8e3cd368be4165b2a9504aada7e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc5250a8a141309ce8b2085cf40a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcbe93cbdd948bc87925001bd1557fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9ca28e7fbf4e4b9c08464af00cc19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa7d907a12446e0bbd28cfce15b2728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbce034a47a54a16b51a9304f15dd6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01a609bdc174e1aa2a713a1146ff456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "## Параметры кванизации\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained( model_id, device_map=\"auto\",quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_4bit,\n",
    "        tokenizer=tokenizer,\n",
    "        use_cache=True,\n",
    "        device_map=\"auto\",\n",
    "        max_length=500,\n",
    "        do_sample=True,\n",
    "        top_k=5,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2802d0-e957-4f0c-9b72-aa4e9e5070cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16f914fa-a269-4951-b2a2-1d243065f15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ad830-d0f6-4fe9-a56d-6a961503d91e",
   "metadata": {},
   "source": [
    "#### Проверим как модель генерирует \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d682f677-f24c-4a57-b67f-96f0ce4f064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='<s>[INST] Generate 5 different ads for keyword \\'buy iphone 25\\' without emoji for 100 symbols. Put it on list [/INST] 1. \"Buy an iPhone 25 for just $25 at our online store. Limited stock available. Hurry!\"\\n\\n2. \"Get the latest technology with an iPhone 25. Buy now for only $25. Free shipping!\"\\n\\n3. \"Own an iPhone 25 for an unbelievable price of $25. Secure your order today!\"\\n\\n4. \"Upgrade to a new iPhone 25. Buy it now for just $25 and enjoy a superior smartphone experience.\"\\n\\n5. \"Bargain alert: iPhone 25 for only $25. Don\\'t miss this amazing deal! Order now.\"\\n\\n- 1. \"Buy an iPhone 25 with a discounted price of $25\"\\n- 2. \"Get a brand new iPhone 25 for $25, limited time offer!\"\\n- 3. \"Experience the power of an iPhone 25, now only $25\"\\n- 4. \"Buy an iPhone 25 for the price of a cheap smartphone\"\\n- 5. \"Score a deal with an iPhone 25, just $25!\"\\n\\n[List]:\\n1. Buy an iPhone 25 for just $25 at our online store.\\n2. Get the latest technology with an iPhone 25. Buy now for only $25.\\n3. Own an iPhone 25 for an unbelievable price of $25.\\n4. Upgrade to a new iPhone 25. Buy it now for just $25.\\n5. Bargain alert: iPhone 25 for only $25. Don\\'t miss this amazing deal!\\n6. Buy an iPhone 25 with a discounted price of $25.\\n7. Get a brand new iPhone 25 for $25, limited time offer!\\n8. Experience the power of an iPhone 25, now only $25.\\n9. Buy an iPhone 25 for the price of a cheap smartphone.\\n10. Score a deal with an iPhone ')]] llm_output=None run=[RunInfo(run_id=UUID('c8654c55-5cf8-4e50-ab22-b9b077722528'))]\n"
     ]
    }
   ],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "#model.to(device)\n",
    "\n",
    "\n",
    "txt = [\"<s>[INST] Generate 5 different ads for keyword 'buy iphone 25' without emoji for 100 symbols. Put it on list [/INST]\"]\n",
    "generated_ids = llm.generate(txt, max_new_tokens=500, do_sample=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42bd00-67fd-4b5a-a7a6-8e5ac28ac03a",
   "metadata": {},
   "source": [
    "##### На первый взгляд неплохо, но есть проблемы : модель допускает критичные неточности - в частности, описывает стоимость устройства, даёт информацию о скидках ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b195a82-2580-4e3d-a913-e50c1e3ffa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='<s>[INST] Generate 3 different ad title for keyword \\'buy new ford mustang\\' without emoji for 40 symbols [/INST] 1. \"Buy a New Ford Mustang: Experience American Power\"\\n\\n2. \"New Ford Mustang for Sale: Modern Muscle and Thrills\"\\n\\n3. \"Join the Legend: Purchase a New Ford Mustang Today\"\\n\\nAll of these titles are designed to appeal to potential buyers of a new Ford Mustang and convey a sense of excitement and desirability around the car. They also keep within the 40-symbol limit.')]] llm_output=None run=[RunInfo(run_id=UUID('eb8c0f0e-debc-4f91-8418-efc8c172d2ed'))]\n"
     ]
    }
   ],
   "source": [
    "txt = [\"<s>[INST] Generate 3 different ad title for keyword 'buy new ford mustang' without emoji for 40 symbols [/INST]\"]\n",
    "generated = llm.generate(txt, max_new_tokens=500, do_sample=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0481e42f-c7a6-475e-97e0-f07a11e90921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', '<s>[INST] Generate 3 different ad title for keyword \\'buy new ford mustang\\' without emoji for 40 symbols [/INST] 1. \"Buy a New Ford Mustang: Experience American Power\"\\n\\n2. \"New Ford Mustang for Sale: Modern Muscle and Thrills\"\\n\\n3. \"Join the Legend: Purchase a New Ford Mustang Today\"\\n\\nAll of these titles are designed to appeal to potential buyers of a new Ford Mustang and convey a sense of excitement and desirability around the car. They also keep within the 40-symbol limit.')\n",
      "('generation_info', None)\n",
      "('type', 'Generation')\n"
     ]
    }
   ],
   "source": [
    "for g in generated.generations[0][0]:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc0a417a-c054-4502-85a9-fd73d217e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__func__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(generated.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c81066f-be06-4359-a7a8-ca79597c2710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='<s>[INST] Generate 3 different ad title for keyword \\'buy new ford mustang\\' without emoji for 40 symbols [/INST] 1. \"Buy a New Ford Mustang: Experience American Power\"\\n\\n2. \"New Ford Mustang for Sale: Modern Muscle and Thrills\"\\n\\n3. \"Join the Legend: Purchase a New Ford Mustang Today\"\\n\\nAll of these titles are designed to appeal to potential buyers of a new Ford Mustang and convey a sense of excitement and desirability around the car. They also keep within the 40-symbol limit.')]], llm_output=None, run=[RunInfo(run_id=UUID('eb8c0f0e-debc-4f91-8418-efc8c172d2ed'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44ff8f96-2910-4873-aa41-391187b77cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='<s>[INST] Generate 3 different ads for keyword \\'buy new ford mustang\\' without emoji for 100 symbols [/INST] 1. \"Buy a New Ford Mustang and Experience Unmatched Power & Style. Limited Time Offer: Extra 5% Off MSRP.\"\\n\\n2. \"Upgrade to a New Ford Mustang. Sleek Design, Powerful Engine, Advanced Technology. Financing Available.\"\\n\\n3. \"Get the Heart-Pumping Performance of a New Ford Mustang. Order Yours Today & Save $1,000 on MSRP. Act Fast!\"')]] llm_output=None run=[RunInfo(run_id=UUID('c1123e4d-65e2-48ba-acef-461f8de8a9ed'))]\n"
     ]
    }
   ],
   "source": [
    "txt = [\"<s>[INST] Generate 3 different ads for keyword 'buy new ford mustang' without emoji for 100 symbols [/INST]\"]\n",
    "generated = llm.generate(txt, max_new_tokens=500, do_sample=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "136f0877-4d28-4314-9644-e1069255d061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text=\"<s>[INST] There are five classes: 'auto','phone','animal','finance','travel'. What class has word 'Ford Mustang'? [/INST] The class for the word 'Ford Mustang' would be 'auto' as it is a type of automobile.\")]] llm_output=None run=[RunInfo(run_id=UUID('3f8313ef-dddc-41d8-a128-0744c44cdbf3'))]\n"
     ]
    }
   ],
   "source": [
    "txt = [\"<s>[INST] There are five classes: 'auto','phone','animal','finance','travel'. What class has word 'Ford Mustang'? [/INST]\"]\n",
    "generated = llm.generate(txt, max_new_tokens=500, do_sample=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88c67f30-a589-4c4d-b733-f5cb68062ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
